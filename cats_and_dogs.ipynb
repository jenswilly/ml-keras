{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source directory\n",
    "original_dataset_dir = '/Users/jenswilly/Downloads/train'\n",
    "\n",
    "# Target directory\n",
    "base_dir = '/Users/jenswilly/Desktop/ML/cats_and_dogs_small'\n",
    "os.mkdir( base_dir )\n",
    "\n",
    "# Create directories\n",
    "sets = ['train', 'validation', 'test']\n",
    "categories = ['cats', 'dogs']\n",
    "\n",
    "for set in sets:\n",
    "    set_dir = os.path.join( base_dir, set )\n",
    "    os.mkdir( set_dir )\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join( set_dir, category )\n",
    "        os.mkdir( category_dir )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy files into targets dirs\n",
    "categories = ['cat', 'dog']  # Without plurals s since the filenames doesn't end in s but directories do\n",
    "dir_counts = { 'train': 2000, 'validation': 1000, 'test': 1000 }\n",
    "offset = 0\n",
    "\n",
    "for directory, count in dir_counts.items():\n",
    "    for category in categories:\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(offset, offset+count)]\n",
    "        for fname in fnames:\n",
    "            src = os.path.join( original_dataset_dir, fname )\n",
    "            dst = os.path.join( base_dir, directory, category + \"s\", fname ) # Adding \"s\" to the category directory name\n",
    "            shutil.copyfile( src, dst )\n",
    "    offset += count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add( layers.Conv2D( 32, (3,3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add( layers.MaxPooling2D( (2,2) ))\n",
    "model.add( layers.Conv2D( 64, (3, 3), activation='relu')) \n",
    "model.add( layers.MaxPooling2D( (2, 2) )) \n",
    "model.add( layers.Conv2D( 128, (3, 3), activation='relu')) \n",
    "model.add( layers.MaxPooling2D( (2, 2) )) \n",
    "model.add( layers.Conv2D( 128, (3, 3), activation='relu')) \n",
    "model.add( layers.MaxPooling2D( (2, 2 ))) \n",
    "model.add(layers.Flatten())\n",
    "model.add( layers.Dense(512, activation='relu')) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile( loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop( lr=1e-4 ),\n",
    "             metrics=['acc'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator( rescale=1./255 )\n",
    "test_datagen = ImageDataGenerator( rescale=1./255 )\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train' )\n",
    "validation_dir = os.path.join( base_dir, 'validation' )\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( train_dir,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary' )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory( validation_dir,\n",
    "                                                       target_size=(150, 150),\n",
    "                                                       batch_size=20,\n",
    "                                                       class_mode='binary' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape:  (20, 150, 150, 3)\n",
      "labels batch shape:  (20,)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print( \"data batch shape: \", data_batch.shape )\n",
    "    print( \"labels batch shape: \", labels_batch.shape )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 35s 347ms/step - loss: 0.0987 - acc: 0.9695 - val_loss: 0.8821 - val_acc: 0.7680\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 36s 360ms/step - loss: 0.0907 - acc: 0.9685 - val_loss: 1.5509 - val_acc: 0.7750\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 36s 357ms/step - loss: 0.0795 - acc: 0.9740 - val_loss: 0.2968 - val_acc: 0.7830\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.0793 - acc: 0.9760 - val_loss: 0.7190 - val_acc: 0.7660\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 0.0679 - acc: 0.9770 - val_loss: 0.5282 - val_acc: 0.7760\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.0744 - acc: 0.9725 - val_loss: 0.4828 - val_acc: 0.7560\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.0502 - acc: 0.9885 - val_loss: 0.7119 - val_acc: 0.7790\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0605 - acc: 0.9825 - val_loss: 1.2789 - val_acc: 0.7310\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 36s 365ms/step - loss: 0.0564 - acc: 0.9820 - val_loss: 0.1470 - val_acc: 0.7800\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0424 - acc: 0.9905 - val_loss: 1.2629 - val_acc: 0.7620\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 37s 375ms/step - loss: 0.0406 - acc: 0.9890 - val_loss: 1.2472 - val_acc: 0.7630\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0413 - acc: 0.9875 - val_loss: 0.7702 - val_acc: 0.7880\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.0297 - acc: 0.9915 - val_loss: 0.3152 - val_acc: 0.7850\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.0339 - acc: 0.9910 - val_loss: 0.7690 - val_acc: 0.7580\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.0261 - acc: 0.9925 - val_loss: 1.1953 - val_acc: 0.7730\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.0418 - acc: 0.9840 - val_loss: 0.8159 - val_acc: 0.7710\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 37s 371ms/step - loss: 0.0198 - acc: 0.9965 - val_loss: 1.2375 - val_acc: 0.7490\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 38s 376ms/step - loss: 0.0254 - acc: 0.9930 - val_loss: 1.1840 - val_acc: 0.7750\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.0202 - acc: 0.9940 - val_loss: 1.0149 - val_acc: 0.7620\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.0223 - acc: 0.9930 - val_loss: 2.2073 - val_acc: 0.8010\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.0255 - acc: 0.9940 - val_loss: 1.6631 - val_acc: 0.7560\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 0.0171 - acc: 0.9960 - val_loss: 1.8312 - val_acc: 0.7700\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0186 - acc: 0.9930 - val_loss: 3.0662 - val_acc: 0.7410\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.0215 - acc: 0.9935 - val_loss: 0.4468 - val_acc: 0.7830\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 37s 366ms/step - loss: 0.0090 - acc: 0.9985 - val_loss: 0.7171 - val_acc: 0.7770\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 0.0171 - acc: 0.9960 - val_loss: 2.4064 - val_acc: 0.7760\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0179 - acc: 0.9925 - val_loss: 1.7187 - val_acc: 0.7830\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 37s 369ms/step - loss: 0.0141 - acc: 0.9955 - val_loss: 2.3071 - val_acc: 0.7700\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 37s 374ms/step - loss: 0.0135 - acc: 0.9950 - val_loss: 0.6719 - val_acc: 0.7720\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 37s 368ms/step - loss: 0.0114 - acc: 0.9975 - val_loss: 1.6996 - val_acc: 0.7660\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "# Create path to logs and instantiate TensorBoard callback\n",
    "# Uncomment the following two lines and add\n",
    "#   callbacks=[tensorboard_callback] to the .fit_generator() call\n",
    "\n",
    "# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "# tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "history = model.fit_generator( train_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=30,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=50 )\n",
    "# On JWJ MacBook Pro: 35-40 secs/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save( 'cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltest",
   "language": "python",
   "name": "mltest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
